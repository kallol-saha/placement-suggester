{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc347fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDisplay(x, target_dim = 2):\n",
    "    while(x.dim() > target_dim):\n",
    "        x = x[0]\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(points_action, points_anchor):\n",
    "    colors = [\n",
    "    '#1f77b4',  # muted blue\n",
    "    '#ff7f0e',  # safety orange\n",
    "    '#2ca02c',  # cooked asparagus green\n",
    "    '#d62728',  # brick red\n",
    "    '#9467bd',  # muted purple\n",
    "    '#8c564b',  # chestnut brown\n",
    "    '#e377c2',  # raspberry yogurt pink\n",
    "    '#7f7f7f',  # middle gray\n",
    "    '#bcbd22',  # curry yellow-green\n",
    "    '#17becf'   # blue-teal\n",
    "]\n",
    "    skip = 1\n",
    "    points_action_dp = toDisplay(points_action)\n",
    "    points_anchor_dp = toDisplay(points_anchor)\n",
    "    go_data=[\n",
    "        go.Scatter3d(x=points_action_dp[::skip,0], y=points_action_dp[::skip,1], z=points_action_dp[::skip,2], \n",
    "                     mode='markers', marker=dict(size=1, color=colors[0],\n",
    "                     symbol='circle')),\n",
    "        go.Scatter3d(x=points_anchor_dp[::skip,0], y=points_anchor_dp[::skip,1], z=points_anchor_dp[::skip,2], \n",
    "                     mode='markers', marker=dict(size=1, color=colors[1],\n",
    "                     symbol='circle')),\n",
    "    ]\n",
    "    layout = go.Layout(\n",
    "        scene=dict(\n",
    "            aspectmode='data'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=go_data, layout=layout)\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "def plot_multi(plist):\n",
    "    \"\"\"\n",
    "    Args: plist, list of torch arrays of shape, (1,num_points,3)\n",
    "    \"\"\"\n",
    "    colors = [\n",
    "    '#1f77b4',  # muted blue\n",
    "    '#ff7f0e',  # safety orange\n",
    "    '#2ca02c',  # cooked asparagus green\n",
    "    '#d62728',  # brick red\n",
    "    '#9467bd',  # muted purple\n",
    "    '#e377c2',  # raspberry yogurt pink\n",
    "    '#8c564b',  # chestnut brown\n",
    "    '#7f7f7f',  # middle gray\n",
    "    '#bcbd22',  # curry yellow-green\n",
    "    '#17becf'   # blue-teal\n",
    "]\n",
    "    skip = 1\n",
    "    go_data = []\n",
    "    for i in range(len(plist)):\n",
    "        p_dp = toDisplay(plist[i])\n",
    "        plot = go.Scatter3d(x=p_dp[::skip,0], y=p_dp[::skip,1], z=p_dp[::skip,2], \n",
    "                     mode='markers', marker=dict(size=1, color=colors[i],\n",
    "                     symbol='circle'))\n",
    "        go_data.append(plot)\n",
    " \n",
    "    layout = go.Layout(\n",
    "        scene=dict(\n",
    "            aspectmode='data'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=go_data, layout=layout)\n",
    "    fig.show()\n",
    "    return fig\n",
    "    \n",
    "def plot_multi_np(plist):\n",
    "    \"\"\"\n",
    "    Args: plist, list of numpy arrays of shape, (1,num_points,3)\n",
    "    \"\"\"\n",
    "    colors = [\n",
    "    '#1f77b4',  # muted blue\n",
    "    '#ff7f0e',  # safety orange\n",
    "    '#2ca02c',  # cooked asparagus green\n",
    "    '#d62728',  # brick red\n",
    "    '#9467bd',  # muted purple\n",
    "    '#e377c2',  # raspberry yogurt pink\n",
    "    '#8c564b',  # chestnut brown\n",
    "    '#7f7f7f',  # middle gray\n",
    "    '#bcbd22',  # curry yellow-green\n",
    "    '#17becf'   # blue-teal\n",
    "]\n",
    "    skip = 1\n",
    "    go_data = []\n",
    "    for i in range(len(plist)):\n",
    "        p_dp = toDisplay(torch.from_numpy(plist[i]))\n",
    "        plot = go.Scatter3d(x=p_dp[::skip,0], y=p_dp[::skip,1], z=p_dp[::skip,2], \n",
    "                     mode='markers', marker=dict(size=1, color=colors[i],\n",
    "                     symbol='circle'))\n",
    "        go_data.append(plot)\n",
    " \n",
    "    layout = go.Layout(\n",
    "        scene=dict(\n",
    "            aspectmode='data'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=go_data, layout=layout)\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "def xyz2homo(xyz):\n",
    "    \"\"\"\n",
    "    xyz:shape 1,num_points, 3\n",
    "    \"\"\"\n",
    "    num_points = xyz.shape[1]\n",
    "    homo = torch.cat([xyz.squeeze(0).detach().cpu(),torch.ones(num_points,1)],dim=-1)\n",
    "    return homo\n",
    "\n",
    "def transform(T,points):\n",
    "    \"\"\"\n",
    "    points: num_points, 4\n",
    "    \"\"\"\n",
    "    points = torch.permute(points,(-1,-2)) # 4,1000\n",
    "    apply_here= torch.from_numpy(T).cuda()@points.cuda()\n",
    "    apply_here = torch.permute(apply_here, (-1, -2))\n",
    "    return apply_here[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee737fd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if not os.path.exists(\"temp_images\"):\n",
    "#     os.mkdir(\"temp_images\")\n",
    "# for f in glob.glob('temp_images/*'):\n",
    "#     os.remove(f)\n",
    "\n",
    "# for f in files:\n",
    "#     os.remove(f)\n",
    "\n",
    "for filename in glob.glob(\"train_data_duprack_bothmugrack_moveracks/renders/*.npz\")[:5]:\n",
    "    data = np.load(filename)\n",
    "\n",
    "    # Added\n",
    "    xyz = data['clouds']\n",
    "    xyz = np.expand_dims(xyz, 0)\n",
    "    # Added\n",
    "    \n",
    "    fig = plot_multi_np([xyz[:,data['classes']==0],xyz[:,data['classes']==1],xyz[:,data['classes']==2]])    \n",
    "#     fig.write_image(f\"temp_images/{filename.replace('/', '-')}.jpg\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot by Class with numpy input\n",
    "# plot_multi_np([xyz[:,data['classes']==0],xyz[:,data['classes']==1],xyz[:,data['classes']==2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with numpy input\n",
    "# plot_multi_np([xyz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94e3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_points, point_data, action_class, anchor_class, scale = 1):\n",
    "    clouds = point_data['clouds'] \n",
    "    classes = point_data['classes']\n",
    "    points_raw_np = clouds\n",
    "    classes_raw_np = classes\n",
    "\n",
    "    points_action_np = points_raw_np[classes_raw_np == action_class].copy()\n",
    "    points_action_np = scale_worldframe(points_action_np, scale = scale)\n",
    "    \n",
    "    points_anchor_np = points_raw_np[classes_raw_np == anchor_class].copy()\n",
    "    points_anchor_np = scale_worldframe(points_anchor_np, scale = scale)\n",
    "    \n",
    "    points_action_mean_np = points_action_np.mean(axis=0)\n",
    "    points_action_np = points_action_np - points_action_mean_np\n",
    "    points_anchor_np = points_anchor_np - points_action_mean_np\n",
    "\n",
    "    points_action = torch.from_numpy(points_action_np).float().unsqueeze(0)\n",
    "    points_anchor = torch.from_numpy(points_anchor_np).float().unsqueeze(0)\n",
    "    points_action, points_anchor = subsample(num_points,points_action, points_anchor)\n",
    "    return points_action.cuda(), points_anchor.cuda()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c694c8",
   "metadata": {},
   "source": [
    "# How similar are the object positions across training examples by class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/sergeyprokudin/c4bf4059230da8db8256e36524993367\n",
    "def chamfer_distance(x, y, metric='l2', direction='bi'):\n",
    "    \"\"\"Chamfer distance between two point clouds\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy array [n_points_x, n_dims]\n",
    "        first point cloud\n",
    "    y: numpy array [n_points_y, n_dims]\n",
    "        second point cloud\n",
    "    metric: string or callable, default ‘l2’\n",
    "        metric to use for distance computation. Any metric from scikit-learn or scipy.spatial.distance can be used.\n",
    "    direction: str\n",
    "        direction of Chamfer distance.\n",
    "            'y_to_x':  computes average minimal distance from every point in y to x\n",
    "            'x_to_y':  computes average minimal distance from every point in x to y\n",
    "            'bi': compute both\n",
    "    Returns\n",
    "    -------\n",
    "    chamfer_dist: float\n",
    "        computed bidirectional Chamfer distance:\n",
    "            sum_{x_i \\in x}{\\min_{y_j \\in y}{||x_i-y_j||**2}} + sum_{y_j \\in y}{\\min_{x_i \\in x}{||x_i-y_j||**2}}\n",
    "    \"\"\"\n",
    "    \n",
    "    if direction=='y_to_x':\n",
    "        x_nn = NearestNeighbors(n_neighbors=1, leaf_size=1, algorithm='kd_tree', metric=metric).fit(x)\n",
    "        min_y_to_x = x_nn.kneighbors(y)[0]\n",
    "        chamfer_dist = np.mean(min_y_to_x)\n",
    "    elif direction=='x_to_y':\n",
    "        y_nn = NearestNeighbors(n_neighbors=1, leaf_size=1, algorithm='kd_tree', metric=metric).fit(y)\n",
    "        min_x_to_y = y_nn.kneighbors(x)[0]\n",
    "        chamfer_dist = np.mean(min_x_to_y)\n",
    "    elif direction=='bi':\n",
    "        x_nn = NearestNeighbors(n_neighbors=1, leaf_size=1, algorithm='kd_tree', metric=metric).fit(x)\n",
    "        min_y_to_x = x_nn.kneighbors(y)[0]\n",
    "        y_nn = NearestNeighbors(n_neighbors=1, leaf_size=1, algorithm='kd_tree', metric=metric).fit(y)\n",
    "        min_x_to_y = y_nn.kneighbors(x)[0]\n",
    "        chamfer_dist = np.mean(min_y_to_x) + np.mean(min_x_to_y)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid direction type. Supported types: \\'y_x\\', \\'x_y\\', \\'bi\\'\")\n",
    "        \n",
    "    return chamfer_dist\n",
    "\n",
    "def dist_by_class(data1, data2, class_num):\n",
    "    assert class_num in [0, 1, 2]\n",
    "    assert np.all([f in data1.files for f in ['clouds', 'colors', 'classes', 'shapenet_id']])\n",
    "    assert np.all([f in data2.files for f in ['clouds', 'colors', 'classes', 'shapenet_id']])\n",
    "    \n",
    "    points1 = data1['clouds'][data1['classes'] == class_num]\n",
    "    points2 = data2['clouds'][data2['classes'] == class_num]\n",
    "    \n",
    "    return chamfer_distance(points1, points2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb58509",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "data_filenames = glob.glob(\"test_data/renders/*.npz\")\n",
    "dist_matrices = np.zeros((num_classes, len(data_filenames), len(data_filenames)))\n",
    "\n",
    "for i, filename1 in enumerate(data_filenames):\n",
    "    for j, filename2 in enumerate(data_filenames):\n",
    "        data1 = np.load(filename1)\n",
    "        data2 = np.load(filename2)\n",
    "        for class_num in list(range(num_classes)):\n",
    "            dist_matrices[class_num, i, j] = dist_by_class(data1, data2, class_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942dcc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_class = [np.sum(dist_matrices[c]) / (np.prod(dist_matrices[c].shape) - len(dist_matrices[c])) for c in list(range(num_classes))]\n",
    "print(\"average per class\", avg_per_class)\n",
    "print(np.array_str(dist_matrices, precision=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa104b27",
   "metadata": {},
   "source": [
    "# Duplicate rack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c796a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"train_data/renders/3_teleport_obj_points.npz\")\n",
    "# data = np.load(\"/home/bokorn/src/ndf_robot/data/renders/0_init_obj_points.npz\", allow_pickle=True)\n",
    "\n",
    "def duplicate_rack(data, translation=np.array([-0.3, 0, 0]), change_mug_target=False, max_points=float('inf'), datatype=\"points_only\"):\n",
    "    # rand_mug_target: if True, randomly place the mug on either the left or right rack\n",
    "    # translation is the translation of rack 2 relative to the original rack\n",
    "\n",
    "    if datatype == \"points_only\":\n",
    "\n",
    "    elif datatype == \"data_dict\":\n",
    "        data = {k: data[k] for k in data.files} # convert to dict\n",
    "\n",
    "        rack_cloud = data['clouds'][data['classes'] == 1]\n",
    "        rack_cloud = rack_cloud + translation\n",
    "\n",
    "        rack_classes = np.tile(data['classes'][data['classes'] == 1][0], (len(rack_cloud)))\n",
    "\n",
    "        rack_colors = data['colors'][data['classes'] == 1]\n",
    "\n",
    "        data['clouds'] = np.concatenate([data['clouds'], rack_cloud], axis=0)\n",
    "        data['classes'] = np.concatenate([data['classes'], rack_classes], axis=0)\n",
    "        data['colors'] = np.concatenate([data['colors'], rack_cloud], axis=0)\n",
    "\n",
    "        if change_mug_target:\n",
    "            # Put the mug on the new rack\n",
    "            data['clouds'][data['classes'] == 0] = data['clouds'][data['classes'] == 0] + translation\n",
    "        if len(data['clouds']) > max_points:\n",
    "            idxs = np.random.choice(np.arange(0, len(data['clouds'])), size=(max_points,))\n",
    "            data['clouds'] = data['clouds'][idxs]\n",
    "            data['classes'] = data['classes'][idxs]\n",
    "            data['colors'] = data['colors'][idxs]\n",
    "\n",
    "        return data\n",
    "\n",
    "data = duplicate_rack(data, translation=np.array([-0.3, 0.3, 0]), change_mug_target=True)#, max_points=3000)\n",
    "\n",
    "# np.savez(\"/home/bokorn/src/ndf_robot/data/renders/0_init_obj_points.npz\", **data)\n",
    "\n",
    "xyz = data['clouds']\n",
    "xyz = np.expand_dims(xyz, 0)\n",
    "\n",
    "plot_multi_np([xyz[:,data['classes']==0],xyz[:,data['classes']==1],xyz[:,data['classes']==2]])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert data\n",
    "\n",
    "# BASE_T = np.array([-0.3, 0, 0])\n",
    "# PERTURB_LIMS = ((-0.05, 0.05), (-0.1, 0.1), (0, 0))\n",
    "\n",
    "# def get_perturb():\n",
    "#     p0 = np.random.random()*(PERTURB_LIMS[0][1] - PERTURB_LIMS[0][0]) + PERTURB_LIMS[0][0]\n",
    "#     p1 = np.random.random()*(PERTURB_LIMS[1][1] - PERTURB_LIMS[1][0]) + PERTURB_LIMS[1][0]\n",
    "#     return np.array([p0, p1, 0])\n",
    "\n",
    "# for in_folder in ['train_data', 'test_data']:\n",
    "#     out_folder = f\"{in_folder}_duprack_bothmugrack_moveracks\"\n",
    "#     Path(f\"{out_folder}/renders/\").mkdir(parents=True, exist_ok=True)\n",
    "#     for filename in glob.glob(f\"{in_folder}/renders/*.npz\"):\n",
    "#         data = np.load(filename)\n",
    "#         duped_data = duplicate_rack(data, translation=BASE_T+get_perturb(), change_mug_target=False)\n",
    "#         np.savez(f\"{out_folder}/renders/{filename.split('/')[-1][:-4]}.npz\", **duped_data)\n",
    "        \n",
    "#         data = np.load(filename)\n",
    "#         duped_data = duplicate_rack(data, translation=BASE_T+get_perturb(), change_mug_target=True)\n",
    "#         np.savez(f\"{out_folder}/renders/999{filename.split('/')[-1][:-4]}.npz\", **duped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls train_data_duprack_randmugrack/renders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1a095",
   "metadata": {},
   "source": [
    "# Duplicate arm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2947dfea",
   "metadata": {},
   "source": [
    "## Get the rack arm to duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"train_data/renders/4_teleport_obj_points.npz\")\n",
    "\n",
    "RACK_CFG = {\n",
    "    'RACK_CENTER_X': 0.59, \n",
    "    'RACK_CENTER_Y': 0.26,\n",
    "    'RACK_R': (0.61-0.56)/2,\n",
    "    'ARM_R': (0.6-0.58)/2,\n",
    "    'ARM_LEN': 0.26 - 0.147 - (0.61-0.56)/2,\n",
    "    'ARM_Z_BOTTOM': 1.1,\n",
    "    'ARM_Z_TOP': 1.24\n",
    "}\n",
    "\n",
    "def get_rack_arm_idxs(data, rack_cfg=RACK_CFG):\n",
    "    RACK_CENTER_X = rack_cfg['RACK_CENTER_X']\n",
    "    RACK_CENTER_Y = rack_cfg['RACK_CENTER_Y']\n",
    "    RACK_R = rack_cfg['RACK_R']\n",
    "    ARM_R = rack_cfg['ARM_R']\n",
    "    ARM_LEN = rack_cfg['ARM_LEN']\n",
    "    ARM_Z_BOTTOM = rack_cfg['ARM_Z_BOTTOM']\n",
    "    ARM_Z_TOP = rack_cfg['ARM_Z_TOP']\n",
    "\n",
    "    rack_cloud = data['clouds'][data['classes'] == 1]\n",
    "    rack_classes = np.tile(data['classes'][data['classes'] == 1][0], (len(rack_cloud)))\n",
    "    rack_colors = data['colors'][data['classes'] == 1]\n",
    "\n",
    "    rack_arm_idxs = np.where(np.logical_and.reduce([\n",
    "        rack_cloud[:,0] < RACK_CENTER_X+ARM_R, rack_cloud[:,0] > RACK_CENTER_X-ARM_R, \\\n",
    "        rack_cloud[:,1] < RACK_CENTER_Y-RACK_R+0.01, rack_cloud[:,1] > RACK_CENTER_Y-RACK_R-ARM_LEN, \\\n",
    "        rack_cloud[:,2] < ARM_Z_TOP, rack_cloud[:,2] > ARM_Z_BOTTOM\n",
    "    ]))\n",
    "\n",
    "    rack_idxs = np.where(data['classes'] == 1)[0]\n",
    "\n",
    "    arm_idxs = rack_idxs[rack_arm_idxs]\n",
    "\n",
    "    return arm_idxs\n",
    "\n",
    "def relabel_rack_arm_idxs(data):\n",
    "    data = {k: data[k] for k in data.files} # convert to dict\n",
    "    \n",
    "    rack_arm_idxs = get_rack_arm_idxs(data)\n",
    "\n",
    "    data['classes'][rack_arm_idxs] = 3\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = relabel_rack_arm_idxs(data)\n",
    "\n",
    "xyz = data['clouds']\n",
    "xyz = np.expand_dims(xyz, 0)\n",
    "\n",
    "plot_multi_np([xyz[:,data['classes']==0],xyz[:,data['classes']==1],xyz[:,data['classes']==2],xyz[:,data['classes']==3]])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"train_data/renders/4_teleport_obj_points.npz\")\n",
    "\n",
    "def duplicate_arm(data, rack_cfg=RACK_CFG, change_mug_target=False):\n",
    "    data = {k: data[k] for k in data.files} # convert to dict\n",
    "\n",
    "    THETA = np.pi/2\n",
    "    TRANSLATE = np.array([0, 0, 0.1])\n",
    "    rotation_mat = np.array([\n",
    "        [np.cos(THETA), -np.sin(THETA), 0],\n",
    "        [np.sin(THETA), np.cos(THETA), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    center = [RACK_CFG['RACK_CENTER_X'], RACK_CFG['RACK_CENTER_Y'], RACK_CFG['ARM_Z_BOTTOM']]\n",
    "\n",
    "    rack_arm_idxs = get_rack_arm_idxs(data, rack_cfg=rack_cfg)\n",
    "    rack_arm_cloud = data['clouds'][rack_arm_idxs]\n",
    "    rack_arm_cloud = (rotation_mat@((rack_arm_cloud - center).T)).T + center + TRANSLATE\n",
    "\n",
    "    rack_arm_classes = np.tile(1, (len(rack_arm_idxs)))\n",
    "\n",
    "    rack_arm_colors = data['colors'][rack_arm_idxs]\n",
    "\n",
    "    data['clouds'] = np.concatenate([data['clouds'], rack_arm_cloud], axis=0)\n",
    "    data['classes'] = np.concatenate([data['classes'], rack_arm_classes], axis=0)\n",
    "    data['colors'] = np.concatenate([data['colors'], rack_arm_cloud], axis=0)\n",
    "\n",
    "    if change_mug_target:\n",
    "        # Put the mug on the new rack\n",
    "        data['clouds'][data['classes'] == 0] = (rotation_mat@((data['clouds'][data['classes'] == 0] - center).T)).T + center + TRANSLATE\n",
    "\n",
    "    return data\n",
    "\n",
    "data = duplicate_arm(data, change_mug_target=True)\n",
    "\n",
    "xyz = data['clouds']\n",
    "xyz = np.expand_dims(xyz, 0)\n",
    "\n",
    "plot_multi_np([xyz[:,data['classes']==0],xyz[:,data['classes']==1],xyz[:,data['classes']==2]])  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c38b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert data\n",
    "# for in_folder in ['train_data', 'test_data']:\n",
    "#     out_folder = f\"{in_folder}_duprackarm_bothmugrack\"\n",
    "#     Path(f\"{out_folder}/renders/\").mkdir(parents=True, exist_ok=True)\n",
    "#     for filename in glob.glob(f\"{in_folder}/renders/*.npz\"):\n",
    "#         data = np.load(filename)\n",
    "#         data = duplicate_arm(data, change_mug_target=False)\n",
    "#         np.savez(f\"{out_folder}/renders/{filename.split('/')[-1][:-4]}.npz\", **data)\n",
    "        \n",
    "#         data = np.load(filename)\n",
    "#         data = duplicate_arm(data, change_mug_target=True)\n",
    "#         np.savez(f\"{out_folder}/renders/999{filename.split('/')[-1][:-4]}.npz\", **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fd75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls train_data_duprackarm_randmugrack/renders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce885a7b",
   "metadata": {},
   "source": [
    "# No colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"train_data_duprack_randmugrack/renders/3_teleport_obj_points.npz\")\n",
    "\n",
    "def gray_out_colors(data):\n",
    "    data = {k: data[k] for k in data.files} # convert to dict\n",
    "    data['colors'][:] = 255/2\n",
    "    return data\n",
    "\n",
    "data = gray_out_colors(data)\n",
    "\n",
    "xyz = data['clouds']\n",
    "xyz = np.expand_dims(xyz, 0)\n",
    "\n",
    "skip = 1\n",
    "points_action_dp = toDisplay(torch.from_numpy(xyz))\n",
    "go_data=[\n",
    "    go.Scatter3d(x=points_action_dp[::skip,0], y=points_action_dp[::skip,1], z=points_action_dp[::skip,2], \n",
    "                 mode='markers', marker=dict(size=1, color=data['colors'],\n",
    "                 symbol='circle')),\n",
    "]\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        aspectmode='data'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go_data, layout=layout)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data\n",
    "for in_folder in ['train_data_duprackarm_bothmugrack', 'test_data_bothrackarm_randmugrack']:\n",
    "    out_folder = f\"{in_folder}_gray\"\n",
    "    Path(f\"{out_folder}/renders/\").mkdir(parents=True, exist_ok=True)\n",
    "    for filename in glob.glob(f\"{in_folder}/renders/*.npz\"):\n",
    "        data = np.load(filename)\n",
    "        data = gray_out_colors(data)\n",
    "        np.savez(f\"{out_folder}/renders/{filename.split('/')[-1]}\", **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo run train_data_duprackarm_randmugrack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
