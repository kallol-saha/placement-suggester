{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7915547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/FlyingGiraffe/vnn/blob/master/models/vn_layers.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "class VNLinear(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VNLinear, self).__init__()\n",
    "        self.map_to_feat = nn.Linear(in_channels, out_channels, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
    "        '''\n",
    "        x_out = self.map_to_feat(x.transpose(1,-1)).transpose(1,-1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class VNLeakyReLU(nn.Module):\n",
    "    def __init__(self, in_channels, share_nonlinearity=False, negative_slope=0.2):\n",
    "        super(VNLeakyReLU, self).__init__()\n",
    "        if share_nonlinearity == True:\n",
    "            self.map_to_dir = nn.Linear(in_channels, 1, bias=False)\n",
    "        else:\n",
    "            self.map_to_dir = nn.Linear(in_channels, in_channels, bias=False)\n",
    "        self.negative_slope = negative_slope\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
    "        '''\n",
    "        d = self.map_to_dir(x.transpose(1,-1)).transpose(1,-1)\n",
    "        dotprod = (x*d).sum(2, keepdim=True)\n",
    "        mask = (dotprod >= 0).float()\n",
    "        d_norm_sq = (d*d).sum(2, keepdim=True)\n",
    "        x_out = self.negative_slope * x + (1-self.negative_slope) * (mask*x + (1-mask)*(x-(dotprod/(d_norm_sq+EPS))*d))\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class VNLinearLeakyReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dim=5, share_nonlinearity=False, negative_slope=0.2):\n",
    "        super(VNLinearLeakyReLU, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.negative_slope = negative_slope\n",
    "        \n",
    "        self.map_to_feat = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.batchnorm = VNBatchNorm(out_channels, dim=dim)\n",
    "        \n",
    "        if share_nonlinearity == True:\n",
    "            self.map_to_dir = nn.Linear(in_channels, 1, bias=False)\n",
    "        else:\n",
    "            self.map_to_dir = nn.Linear(in_channels, out_channels, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
    "        '''\n",
    "        # Linear\n",
    "        p = self.map_to_feat(x.transpose(1,-1)).transpose(1,-1)\n",
    "        # BatchNorm\n",
    "        p = self.batchnorm(p)\n",
    "        # LeakyReLU\n",
    "        d = self.map_to_dir(x.transpose(1,-1)).transpose(1,-1)\n",
    "        dotprod = (p*d).sum(2, keepdims=True)\n",
    "        mask = (dotprod >= 0).float()\n",
    "        d_norm_sq = (d*d).sum(2, keepdims=True)\n",
    "        x_out = self.negative_slope * p + (1-self.negative_slope) * (mask*p + (1-mask)*(p-(dotprod/(d_norm_sq+EPS))*d))\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class VNLinearAndLeakyReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dim=5, share_nonlinearity=False, use_batchnorm='norm', negative_slope=0.2):\n",
    "        super(VNLinearLeakyReLU, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.share_nonlinearity = share_nonlinearity\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.negative_slope = negative_slope\n",
    "        \n",
    "        self.linear = VNLinear(in_channels, out_channels)\n",
    "        self.leaky_relu = VNLeakyReLU(out_channels, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
    "        \n",
    "        # BatchNorm\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        if use_batchnorm != 'none':\n",
    "            self.batchnorm = VNBatchNorm(out_channels, dim=dim, mode=use_batchnorm)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
    "        '''\n",
    "        # Conv\n",
    "        x = self.linear(x)\n",
    "        # InstanceNorm\n",
    "        if self.use_batchnorm != 'none':\n",
    "            x = self.batchnorm(x)\n",
    "        # LeakyReLU\n",
    "        x_out = self.leaky_relu(x)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class VNBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, dim):\n",
    "        super(VNBatchNorm, self).__init__()\n",
    "        self.dim = dim\n",
    "        if dim == 3 or dim == 4:\n",
    "            self.bn = nn.BatchNorm1d(num_features)\n",
    "        elif dim == 5:\n",
    "            self.bn = nn.BatchNorm2d(num_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
    "        '''\n",
    "        # norm = torch.sqrt((x*x).sum(2))\n",
    "        norm = torch.norm(x, dim=2) + EPS\n",
    "        norm_bn = self.bn(norm)\n",
    "        norm = norm.unsqueeze(2)\n",
    "        norm_bn = norm_bn.unsqueeze(2)\n",
    "        x = x / norm * norm_bn\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class VNMaxPool(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(VNMaxPool, self).__init__()\n",
    "        self.map_to_dir = nn.Linear(in_channels, in_channels, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
    "        '''\n",
    "        d = self.map_to_dir(x.transpose(1,-1)).transpose(1,-1)\n",
    "        dotprod = (x*d).sum(2, keepdims=True)\n",
    "        idx = dotprod.max(dim=-1, keepdim=False)[1]\n",
    "        index_tuple = torch.meshgrid([torch.arange(j) for j in x.size()[:-1]]) + (idx,)\n",
    "        x_max = x[index_tuple]\n",
    "        return x_max\n",
    "\n",
    "\n",
    "def mean_pool(x, dim=-1, keepdim=False):\n",
    "    return x.mean(dim=dim, keepdim=keepdim)\n",
    "\n",
    "\n",
    "class VNStdFeature(nn.Module):\n",
    "    def __init__(self, in_channels, dim=4, normalize_frame=False, share_nonlinearity=False, negative_slope=0.2):\n",
    "        super(VNStdFeature, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.normalize_frame = normalize_frame\n",
    "        \n",
    "        self.vn1 = VNLinearLeakyReLU(in_channels, in_channels//2, dim=dim, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
    "        self.vn2 = VNLinearLeakyReLU(in_channels//2, in_channels//4, dim=dim, share_nonlinearity=share_nonlinearity, negative_slope=negative_slope)\n",
    "        if normalize_frame:\n",
    "            self.vn_lin = nn.Linear(in_channels//4, 2, bias=False)\n",
    "        else:\n",
    "            self.vn_lin = nn.Linear(in_channels//4, 3, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
    "        '''\n",
    "        z0 = x\n",
    "        z0 = self.vn1(z0)\n",
    "        z0 = self.vn2(z0)\n",
    "        z0 = self.vn_lin(z0.transpose(1, -1)).transpose(1, -1)\n",
    "        \n",
    "        if self.normalize_frame:\n",
    "            # make z0 orthogonal. u2 = v2 - proj_u1(v2)\n",
    "            v1 = z0[:,0,:]\n",
    "            #u1 = F.normalize(v1, dim=1)\n",
    "            v1_norm = torch.sqrt((v1*v1).sum(1, keepdims=True))\n",
    "            u1 = v1 / (v1_norm+EPS)\n",
    "            v2 = z0[:,1,:]\n",
    "            v2 = v2 - (v2*u1).sum(1, keepdims=True)*u1\n",
    "            #u2 = F.normalize(u2, dim=1)\n",
    "            v2_norm = torch.sqrt((v2*v2).sum(1, keepdims=True))\n",
    "            u2 = v2 / (v2_norm+EPS)\n",
    "\n",
    "            # compute the cross product of the two output vectors        \n",
    "            u3 = torch.cross(u1, u2)\n",
    "            z0 = torch.stack([u1, u2, u3], dim=1).transpose(1, 2)\n",
    "        else:\n",
    "            z0 = z0.transpose(1, 2)\n",
    "        \n",
    "        if self.dim == 4:\n",
    "            x_std = torch.einsum('bijm,bjkm->bikm', x, z0)\n",
    "        elif self.dim == 3:\n",
    "            x_std = torch.einsum('bij,bjk->bik', x, z0)\n",
    "        elif self.dim == 5:\n",
    "            x_std = torch.einsum('bijmn,bjkmn->bikmn', x, z0)\n",
    "        \n",
    "        return x_std, z0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7643b7",
   "metadata": {},
   "source": [
    "# stoof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaedb71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5314,  0.0958, -0.3530, -0.5871],\n",
       "          [-0.4105, -0.0552, -0.3118, -0.1344],\n",
       "          [-0.1209, -0.1266, -0.4457, -0.2126]],\n",
       "\n",
       "         [[-0.1364, -0.3606, -0.1725, -0.0621],\n",
       "          [-0.0611, -0.2165, -0.1024, -0.1355],\n",
       "          [-0.2255, -0.2437, -0.1435, -0.1294]],\n",
       "\n",
       "         [[-0.2854, -0.5192, -0.3109, -0.1842],\n",
       "          [-0.1550, -0.3293, -0.2006, -0.2218],\n",
       "          [-0.3530, -0.3809, -0.2826, -0.2250]],\n",
       "\n",
       "         [[-0.0747,  0.2520,  0.0011, -0.1374],\n",
       "          [-0.0851,  0.1175, -0.0300,  0.0437],\n",
       "          [ 0.1034,  0.1130, -0.0446,  0.0165]],\n",
       "\n",
       "         [[ 0.7530,  0.6643,  0.6702,  0.6480],\n",
       "          [ 0.4898,  0.4983,  0.4883,  0.4002],\n",
       "          [ 0.5751,  0.6181,  0.6921,  0.4566]]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x: point features of shape [B, N_feat, 3, N_samples, ...]\n",
    "x = torch.rand(1, 2, 3, 4)\n",
    "model = VNLinear(2, 5)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8415dd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9996, -0.0061, -0.0275,  0.0000],\n",
       "         [ 0.0059,  1.0000, -0.0064,  0.0000],\n",
       "         [ 0.0275,  0.0063,  0.9996,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  1.0000]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from equivariant_pose_graph.utils.se3 import random_se3\n",
    "R = random_se3(1, rot_var=np.pi/180 * 5, trans_var=0)\n",
    "R.get_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df01620a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 3.  Target sizes: [1, 2, 3, 4].  Tensor sizes: [3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fdc1cf47a4c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 3.  Target sizes: [1, 2, 3, 4].  Tensor sizes: [3]"
     ]
    }
   ],
   "source": [
    "x[:,:,:,:] = R.transform_points(x[:,0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dcd26d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1, 1, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 4)\n",
    "x.unsqueeze(1).view(x.shape[0], -1, x.shape[-1]).transpose(2,1).view(1, 4, 1, 1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c6a6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
